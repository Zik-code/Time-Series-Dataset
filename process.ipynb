{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeb298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed34bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已加载，类型: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载 .npy 文件\n",
    "data = np.load('./processed_data/SMD/machine-1-1_train.npy')\n",
    "print(f\"数据已加载，类型: {type(data)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686ae252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据形状: (28479, 38)\n",
      "数据类型: float64\n",
      "数据维度: 2\n",
      "数据符合38维特征要求\n"
     ]
    }
   ],
   "source": [
    "# 查看数据形状（样本数, 特征数）\n",
    "print(f\"数据形状: {data.shape}\")\n",
    "\n",
    "# 查看数据类型（如 float32, int64 等）\n",
    "print(f\"数据类型: {data.dtype}\")\n",
    "\n",
    "# 查看数据维度\n",
    "print(f\"数据维度: {data.ndim}\")\n",
    "\n",
    "# 查看数据集行数和列数\n",
    "rows, columns = data.shape\n",
    "\n",
    "if columns == 38:\n",
    "    print(\"数据符合38维特征要求\")\n",
    "else:\n",
    "    print(f\"数据维度异常，当前数据特征维度为{columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd96e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已加载，类型: <class 'numpy.ndarray'>\n",
      "\n",
      "=== 基本信息 ===\n",
      "数据形状: (28479, 38)\n",
      "数据类型: float64\n",
      "数据维度: 2\n",
      "\n",
      "=== 整体统计信息 ===\n",
      "数据均值: 0.03460352133889976\n",
      "数据标准差: 0.18277340520395194\n",
      "数据最小值: 0.0\n",
      "数据最大值: 1.0\n",
      "\n",
      "=== 数据前几行内容 ===\n",
      "数据前5行内容：\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "=== 异常值检查 ===\n",
      "数据是否包含 NaN: False\n",
      "数据是否包含无穷大: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_npy_file(file_path):\n",
    "    try:\n",
    "        # 加载数据\n",
    "        data = np.load(file_path)\n",
    "        print(f\"数据已加载，类型: {type(data)}\")\n",
    "        \n",
    "        # 基本信息\n",
    "        print(\"\\n=== 基本信息 ===\")\n",
    "        print(f\"数据形状: {data.shape}\")\n",
    "        print(f\"数据类型: {data.dtype}\")\n",
    "        print(f\"数据维度: {data.ndim}\")\n",
    "        \n",
    "        # 统计信息\n",
    "        print(\"\\n=== 整体统计信息 ===\")\n",
    "        print(f\"数据均值: {data.mean()}\")\n",
    "        print(f\"数据标准差: {data.std()}\")\n",
    "        print(f\"数据最小值: {data.min()}\")\n",
    "        print(f\"数据最大值: {data.max()}\")\n",
    "        \n",
    "        # 前几行信息\n",
    "        rows, columns = data.shape\n",
    "        print(\"\\n=== 数据前几行内容 ===\")\n",
    "        if rows < 5:\n",
    "            print(f\"数据前{rows}行内容：\")\n",
    "            print(data[:rows, :])\n",
    "        else:\n",
    "            print(\"数据前5行内容：\")\n",
    "            print(data[:5, :])\n",
    "        \n",
    "        # 异常值检查\n",
    "        print(\"\\n=== 异常值检查 ===\")\n",
    "        has_nan = np.isnan(data).any()\n",
    "        print(f\"数据是否包含 NaN: {has_nan}\")\n",
    "        \n",
    "        has_inf = np.isinf(data).any()\n",
    "        print(f\"数据是否包含无穷大: {has_inf}\")\n",
    "        \n",
    "        # 如果有NaN，统计每列的NaN数量\n",
    "        if has_nan:\n",
    "            print(\"\\n=== NaN 分布 ===\")\n",
    "            for i in range(data.shape[1]):\n",
    "                nan_count = np.isnan(data[:, i]).sum()\n",
    "                if nan_count > 0:\n",
    "                    print(f\"特征 {i+1} 包含 {nan_count} 个 NaN 值\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：文件 '{file_path}' 不存在\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误：加载文件时发生异常: {e}\")\n",
    "        return None\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = './processed_data/SMD/machine-1-1_labels.npy'  # 替换为你的文件路径\n",
    "    data = inspect_npy_file(file_path)\n",
    "    \n",
    "    # 如果数据加载成功，可以进一步处理\n",
    "    if data is not None:\n",
    "        # 例如：保存数据的前100行到新文件\n",
    "        np.save('your_data_first_100.npy', data[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5ccd45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mTraining LSTM_AD on SMD\u001b[0m\n",
      "Loaded dataset from processed_data\\SMD\n",
      "Train shape: (28479, 38), Test shape: (28479, 38), Labels shape: (28479, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:18,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.009853, LR: 0.002000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:09<00:13,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.003040, LR: 0.002000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:17<00:12,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.003036, LR: 0.002000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:26<00:07,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.003031, LR: 0.002000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.001303, LR: 0.001800\n",
      "Training time: 31.60 seconds\n",
      "Model saved to checkpoints/LSTM_AD_SMD/\n",
      "\u001b[95mEvaluating LSTM_AD on SMD\u001b[0m\n",
      "\n",
      "Per-feature Results:\n",
      "    Feature  Precision    Recall  F1-Score\n",
      "0       0.0   0.315381  0.946617  0.473130\n",
      "1       1.0   0.156659  0.462471  0.234039\n",
      "2       2.0   0.108661  0.529412  0.180313\n",
      "3       3.0   0.103463  0.567059  0.174997\n",
      "4       4.0   0.000000  0.000000  0.000000\n",
      "5       5.0   0.039037  0.409747  0.071283\n",
      "6       6.0   0.024401  0.102888  0.039446\n",
      "7       7.0   0.000000  0.000000  0.000000\n",
      "8       8.0   0.260467  0.263592  0.262020\n",
      "9       9.0   0.225324  0.588722  0.325911\n",
      "10     10.0   0.143590  0.175686  0.158025\n",
      "11     11.0   0.338600  0.225564  0.270758\n",
      "12     12.0   0.444877  0.257218  0.325968\n",
      "13     13.0   0.140866  0.143982  0.142407\n",
      "14     14.0   0.258498  0.245219  0.251684\n",
      "15     15.0   0.140635  0.177255  0.156836\n",
      "16     16.0   0.000000  0.000000  0.000000\n",
      "17     17.0   0.000000  0.000000  0.000000\n",
      "18     18.0   0.040414  0.592058  0.075663\n",
      "19     19.0   0.049042  0.577617  0.090408\n",
      "20     20.0   0.054582  0.590253  0.099924\n",
      "21     21.0   0.053615  0.595668  0.098375\n",
      "22     22.0   0.000000  0.000000  0.000000\n",
      "23     23.0   0.065217  0.373646  0.111052\n",
      "24     24.0   0.100954  0.523137  0.169246\n",
      "25     25.0   0.060017  0.384477  0.103826\n",
      "26     26.0   0.045522  0.550542  0.084092\n",
      "27     27.0   0.109236  0.538039  0.181602\n",
      "28     28.0   0.072695  0.074007  0.073345\n",
      "29     29.0   0.030845  1.000000  0.059843\n",
      "30     30.0   0.053960  0.590253  0.098881\n",
      "31     31.0   0.054198  0.568592  0.098963\n",
      "32     32.0   0.066980  0.102888  0.081139\n",
      "33     33.0   0.138989  0.138989  0.138989\n",
      "34     34.0   0.049505  0.568592  0.091080\n",
      "35     35.0   0.048667  0.566787  0.089637\n",
      "36     36.0   0.000000  0.000000  0.000000\n",
      "37     37.0   0.000000  0.000000  0.000000\n",
      "\n",
      "Overall Results:\n",
      "Precision: 0.3604\n",
      "Recall: 0.9265\n",
      "F1-Score: 0.5189\n",
      "TP: 2471.0000\n",
      "FP: 4386.0000\n",
      "FN: 196.0000\n",
      "TN: 21426.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "# 设置颜色输出\n",
    "class color:\n",
    "    HEADER = '\\033[95m'\n",
    "    GREEN = '\\033[92m'\n",
    "    BOLD = '\\033[1m'\n",
    "    ENDC = '\\033[0m'\n",
    "\n",
    "# 修复后的LSTM_AD模型定义\n",
    "class LSTM_AD(nn.Module):\n",
    "    def __init__(self, feats, window_size=10):\n",
    "        super(LSTM_AD, self).__init__()\n",
    "        self.name = 'LSTM_AD'\n",
    "        self.lr = 0.002\n",
    "        self.n_feats = feats\n",
    "        self.n_hidden = 64\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # 修改LSTM层以处理窗口数据\n",
    "        self.lstm = nn.LSTM(feats, self.n_hidden, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.n_hidden, self.n_feats, batch_first=True)\n",
    "        self.fcn = nn.Sequential(nn.Linear(self.n_feats, self.n_feats), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 重塑输入以匹配[batch, seq_len, features]\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, self.window_size, self.n_feats)\n",
    "        \n",
    "        hidden = (torch.rand(1, batch_size, self.n_hidden, dtype=torch.float32).to(x.device), \n",
    "                  torch.randn(1, batch_size, self.n_hidden, dtype=torch.float32).to(x.device))\n",
    "        hidden2 = (torch.rand(1, batch_size, self.n_feats, dtype=torch.float32).to(x.device), \n",
    "                   torch.randn(1, batch_size, self.n_feats, dtype=torch.float32).to(x.device))\n",
    "        \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out, hidden2 = self.lstm2(out, hidden2)\n",
    "        out = self.fcn(out[:, -1, :])  # 只取最后一个时间步的输出\n",
    "        return out\n",
    "\n",
    "# 修复后的数据窗口化函数\n",
    "def convert_to_windows(data, model):\n",
    "    windows = []\n",
    "    w_size = model.window_size\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if i >= w_size:\n",
    "            w = data[i - w_size:i]\n",
    "        else:\n",
    "            # 处理序列开始部分的填充\n",
    "            padding = data[0].repeat(w_size - i, 1)\n",
    "            w = torch.cat([padding, data[0:i]])\n",
    "        windows.append(w)  # 不再展平，保持[window_size, features]形状\n",
    "    \n",
    "    return torch.stack(windows)\n",
    "\n",
    "# 加载数据集\n",
    "def load_dataset(dataset):\n",
    "    folder = os.path.join(\"processed_data\", dataset)  # 修改为processed/SMD目录\n",
    "    if not os.path.exists(folder):\n",
    "        raise Exception(f'Processed Data not found in {folder}')\n",
    "    \n",
    "    # 加载SMD数据\n",
    "    train = np.load(os.path.join(folder, 'machine-1-1_train.npy'))\n",
    "    test = np.load(os.path.join(folder, 'machine-1-1_test.npy'))\n",
    "    labels = np.load(os.path.join(folder, 'machine-1-1_labels.npy'))\n",
    "    \n",
    "    print(f\"Loaded dataset from {folder}\")\n",
    "    print(f\"Train shape: {train.shape}, Test shape: {test.shape}, Labels shape: {labels.shape}\")\n",
    "    \n",
    "    return train, test, labels\n",
    "\n",
    "# 训练函数\n",
    "def train(model, train_loader, optimizer, scheduler, num_epochs=5):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.float()  # 确保数据为float32\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data[:, -1, :])  # 比较预测值与窗口最后一个时间步\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        accuracy_list.append((avg_loss, lr))\n",
    "        tqdm.write(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}, LR: {lr:.6f}')\n",
    "    \n",
    "    return accuracy_list\n",
    "\n",
    "# 测试函数\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    all_losses = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.float()  # 确保数据为float32\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data[:, -1, :])  # 比较预测值与窗口最后一个时间步\n",
    "            all_losses.append(loss.cpu().numpy())\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(all_losses), np.vstack(all_predictions)\n",
    "\n",
    "# POT评估函数（Peak Over Threshold）\n",
    "def pot_eval(train_loss, test_loss, labels):\n",
    "    # 简化版POT评估（实际应用中可能需要更复杂的实现）\n",
    "    # 这里使用训练损失的95%分位数作为阈值\n",
    "    threshold = np.quantile(train_loss, 0.95)\n",
    "    \n",
    "    # 预测异常\n",
    "    predictions = (test_loss > threshold).astype(int)\n",
    "    \n",
    "    # 计算指标\n",
    "    tp = np.sum((predictions == 1) & (labels == 1))\n",
    "    fp = np.sum((predictions == 1) & (labels == 0))\n",
    "    fn = np.sum((predictions == 0) & (labels == 1))\n",
    "    tn = np.sum((predictions == 0) & (labels == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'TP': tp,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'TN': tn\n",
    "    }, predictions\n",
    "\n",
    "# 保存模型\n",
    "def save_model(model, optimizer, scheduler, epoch, accuracy_list, dataset):\n",
    "    folder = f'checkpoints/LSTM_AD_{dataset}/'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'accuracy_list': accuracy_list\n",
    "    }, f'{folder}/model.ckpt')\n",
    "    print(f\"Model saved to {folder}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    dataset = 'SMD'\n",
    "    print(f\"{color.HEADER}Training LSTM_AD on {dataset}{color.ENDC}\")\n",
    "    \n",
    "    # 加载数据\n",
    "    train_data, test_data, labels = load_dataset(dataset)\n",
    "    \n",
    "    # 转换为PyTorch张量，使用float32（单精度）\n",
    "    train_tensor = torch.FloatTensor(train_data)\n",
    "    test_tensor = torch.FloatTensor(test_data)\n",
    "    labels_tensor = torch.FloatTensor(labels)\n",
    "    \n",
    "    # 修复：动态创建Args对象\n",
    "    args = type('Args', (object,), {\n",
    "        'model': 'LSTM_AD',\n",
    "        'dataset': dataset,\n",
    "        'test': False,\n",
    "        'retrain': False,\n",
    "        'less': False\n",
    "    })()\n",
    "    \n",
    "    # 初始化模型，传入窗口大小和特征数\n",
    "    window_size = 10\n",
    "    model = LSTM_AD(train_data.shape[1], window_size)\n",
    "    \n",
    "    # 初始化优化器和调度器\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=model.lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, 0.9)\n",
    "    \n",
    "    # 窗口化数据\n",
    "    train_windows = convert_to_windows(train_tensor, model)\n",
    "    test_windows = convert_to_windows(test_tensor, model)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_windows, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_windows, batch_size=64)\n",
    "    \n",
    "    # 训练模型\n",
    "    start_time = time()\n",
    "    accuracy_list = train(model, train_loader, optimizer, scheduler, num_epochs=5)\n",
    "    end_time = time()\n",
    "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # 保存模型\n",
    "    save_model(model, optimizer, scheduler, 5, accuracy_list, dataset)\n",
    "    \n",
    "    # 测试模型\n",
    "    train_loss, _ = test(model, train_loader)\n",
    "    test_loss, predictions = test(model, test_loader)\n",
    "    \n",
    "    # 评估\n",
    "    print(f\"{color.HEADER}Evaluating LSTM_AD on {dataset}{color.ENDC}\")\n",
    "    \n",
    "    # 计算每个特征的评估结果\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(test_loss.shape[1]):\n",
    "        train_feat_loss = train_loss[:, i]\n",
    "        test_feat_loss = test_loss[:, i]\n",
    "        feat_labels = labels[:, i]\n",
    "        \n",
    "        result, _ = pot_eval(train_feat_loss, test_feat_loss, feat_labels)\n",
    "        df = df._append({\n",
    "            'Feature': i,\n",
    "            'Precision': result['Precision'],\n",
    "            'Recall': result['Recall'],\n",
    "            'F1-Score': result['F1-Score']\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    # 计算整体评估结果（平均所有特征）\n",
    "    overall_loss = np.mean(test_loss, axis=1)\n",
    "    overall_labels = (np.sum(labels, axis=1) >= 1).astype(int)\n",
    "    overall_result, _ = pot_eval(np.mean(train_loss, axis=1), overall_loss, overall_labels)\n",
    "    \n",
    "    print(\"\\nPer-feature Results:\")\n",
    "    print(df)\n",
    "    print(\"\\nOverall Results:\")\n",
    "    for key, value in overall_result.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
